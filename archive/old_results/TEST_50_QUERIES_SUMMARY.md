# 50 Query Test Results Summary

## Test Status
- **Total Queries**: 50
- **Completed**: 32/50 (as of latest check)
- **Test Started**: 2025-12-20 14:20
- **Status**: Running

## Training Data Collection

### Current Statistics
- **Total Samples Collected**: 27 (and growing)
- **Average Output Tokens**: 332.78
- **Min Output Tokens**: 7
- **Max Output Tokens**: 1,304
- **Unique Complexities**: 3 (simple, medium, complex)
- **Models Used**: gpt-4o-mini

### Complexity Distribution
- **Simple**: 13 samples
- **Medium**: 11 samples
- **Complex**: 3 samples

### Data Format
The training data is stored in SQLite database `token_prediction_data.db` with the following schema:

```sql
CREATE TABLE token_predictions (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    query TEXT NOT NULL,
    query_length INTEGER NOT NULL,
    complexity TEXT NOT NULL,
    embedding_vector TEXT,  -- JSON array of first 10 dimensions
    predicted_tokens INTEGER,
    actual_output_tokens INTEGER NOT NULL,
    model_used TEXT,
    timestamp TEXT NOT NULL
)
```

### Sample Data Format
Each training sample includes:
- **query**: The original user query
- **query_length**: Number of tokens in the query
- **complexity**: Complexity classification (simple/medium/complex)
- **embedding_vector**: First 10 dimensions of query embedding (JSON array)
- **predicted_tokens**: Predicted max_tokens value (from heuristic or ML model)
- **actual_output_tokens**: Actual tokens generated by LLM
- **model_used**: Model that generated the response
- **timestamp**: ISO timestamp of when data was collected

### Example Sample
```json
{
  "query": "What are the main components of a computer's CPU?",
  "query_length": 11,
  "complexity": "medium",
  "embedding_vector": [0.046, 0.020, -0.0007, ...],
  "predicted_tokens": 545,
  "actual_output_tokens": 327,
  "model_used": "gpt-4o-mini",
  "timestamp": "2025-12-20T14:24:33.851270"
}
```

## Data Export
- **Export File**: `training_data_export_20251220_142434.json`
- **Format**: JSON with metadata and all samples
- **Verification Script**: `verify_training_data.py`

## Test Results Files
- **Latest Results**: `complete_platform_test_results_intermediate_20251220_142849.json`
- **Queries Processed**: 30
- **Optimized Results**: 30
- **Baseline Results**: 30
- **Comparisons**: 30

## Next Steps
1. Wait for test completion (all 50 queries)
2. Final results will be saved to `complete_platform_test_results_YYYYMMDD_HHMMSS.json`
3. Training data will continue to accumulate
4. Regression model can be trained when 500+ samples are available (currently 27)

## Verification
Run `python verify_training_data.py` to:
- Check total samples collected
- View statistics and distributions
- Export data to JSON format
- Verify data format correctness






