# Tokenomics Platform Comprehensive Showcase Report

**Test Period**: 2025-12-13T11:05:24.220182 to 2025-12-13T11:24:22.723464

**Overall Status**: FAILED

## Executive Summary

- **Success Rate**: 76.1%
- **Token Savings**: 27.0%
- **Latency Reduction**: -90.6%
- **Cache Hit Rate**: 0.0%
- **Working Components**: 3
- **Issues Found**: 1

## Component Health

### Memory Layer

- **Status**: FAILED
- **Errors**:
  - 'MemoryCache' object has no attribute 'cache'

### Orchestrator

- **Status**: HEALTHY
- **Details**:
  - default_budget: 4000
  - max_context_tokens: 8000

### Bandit Optimizer

- **Status**: HEALTHY
- **Details**:
  - algorithm: ucb
  - num_strategies: 3
  - strategies: ['cheap', 'balanced', 'premium']

### Quality Judge

- **Status**: HEALTHY
- **Details**:
  - enabled: True
  - model: gpt-4o
  - provider: openai

### LLMLingua Compression

- **Status**: DEGRADED
- **Errors**:
  - LLMLingua not available (using fallback)

## Aggregated Metrics

### Token Metrics

- Total Baseline Tokens: 16,645
- Total Optimized Tokens: 12,144
- Total Savings: 4,501 tokens (27.0%)

### Component Savings

- Memory Layer: 0 tokens
- Orchestrator: 5,252 tokens
- Bandit: 0 tokens
- Compression: 0 tokens

### Cache Statistics

- Hit Rate: 0.0%
- Exact Hits: 0
- Semantic Direct Hits: 0
- Context Hits: 0

### Memory Layer Statistics

- Context Injections: 0
- Context Tokens Injected: 0
- Context Tokens Saved: 0
- Average Similarity: 0.000

## Recommendations

- Install LLMLingua-2 for better compression: pip install llmlingua
- Check LLMLingua-2 installation and initialization. Compression may be using fallback.
- Fix failed components: Memory Layer
- Review warnings and address any issues found

